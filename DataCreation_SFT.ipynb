{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d214ab03-c63e-4ba5-bf01-4553b1c68687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90eee74a-f120-435e-bbb7-4fdeb02d3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_json(\"Data/user.json\")\n",
    "split_df = pd.read_csv(\"Data/split.csv\")\n",
    "label_df = pd.read_csv(\"Data/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee516e9-76da-42b0-8519-ed656672c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_id_list = split_df[split_df['split']=='test']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5328d6-6804-4bea-a38b-30a9cc1498f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_label = pd.merge(user_df,label_df,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc33e90-ddb2-47c6-b403-7718e6ccfc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_account_age(age):\n",
    "    if age == 0:\n",
    "        return \"account created less than a year ago\"\n",
    "    elif age == 1:\n",
    "        return \"account is 1 year old\"\n",
    "    else:\n",
    "        return f\"account is {age} years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0774a5f-aa76-4c1d-aa57-b0ce075de3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (user_df_label['verified'] & user_df_label['protected']),            \n",
    "    (user_df_label['verified'] & ~user_df_label['protected']),           \n",
    "    (~user_df_label['verified'] & user_df_label['protected']),          \n",
    "    (~user_df_label['verified'] & ~user_df_label['protected'])        \n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    'verified and protected',\n",
    "    'verified but not protected',\n",
    "    'protected but not verified',\n",
    "    'neither verified nor protected'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7766466-9a82-4082-878e-8fd6db9ff317",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now(pytz.UTC)\n",
    "user_df_label['account_age'] = user_df_label['created_at'].apply(lambda x: (current_date - x).days / 365.25)\n",
    "user_df_label['account_age'] = user_df_label['account_age'].apply(lambda x: np.nan if x > 19 else x)\n",
    "user_df_label['account_age'] = user_df_label.groupby('label')['account_age'].transform(lambda grp: grp.fillna(grp.mean()))\n",
    "user_df_label['account_age']= user_df_label['account_age'].astype(int)\n",
    "user_df_label['account_age'] = user_df_label['account_age'].apply(classify_account_age)\n",
    "user_df_label['followers_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('followers_count', 0))\n",
    "user_df_label['following_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('following_count', 0))\n",
    "user_df_label['tweet_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('tweet_count', 0))\n",
    "user_df_label['listed_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('listed_count', 0))\n",
    "user_df_label['status'] = np.select(conditions, choices, default='Unknown')\n",
    "user_df_label['has_custom_profile_image'] = user_df_label['profile_image_url'].apply(lambda x: \"does not have a profile picture\" if 'default_profile_images' in x else \"has a profile picture\")\n",
    "user_df_label.drop([\"protected\",\"verified\",\"created_at\",\"public_metrics\",\"entities\",\"location\",\"withheld\",\"pinned_tweet_id\",\"profile_image_url\",\"url\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc71201f-e71a-43de-872f-f7c9dd588e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_label = pd.merge(user_df_label,split_df,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d25b6bd-0cd7-4c18-8e1e-7011d65607a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_df = user_df_label[user_df_label['split']=='train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0db0647-a19f-4eb0-b73a-9832ae731ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_val_df = user_df_label[user_df_label['split']=='val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15267936-fecc-4dcf-b281-703d464b713a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "751089f6-5dbf-4bcd-91ff-d4f7142ea0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data_prompt(feature_list):\n",
    "    user_metadata_text = f\"\"\"\n",
    "    The name of the user is '{feature_list['name']}' with an account username '{feature_list['username']}'. The description for the user profile is '{feature_list['description']}'. The {feature_list['account_age']} and some of the metric of the user is as follows:\n",
    "    The user has {feature_list['followers_count']} followers and follows {feature_list['following_count']} accounts. \n",
    "    The user has posted {feature_list['tweet_count']} tweets and is a member of {feature_list['listed_count']} public list.\n",
    "    The user account is {feature_list['status']} and it {feature_list['has_custom_profile_image']} associated with it.\n",
    "    \"\"\"\n",
    "    return user_metadata_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f2eb018-c51d-4e94-bb94-859de34f7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_finetuning_data(training_data):\n",
    "    \"\"\"Prepares data for fine-tuning with QLoRA.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    for i, row in training_data.iterrows():\n",
    "        prompt_text = get_user_data_prompt(row)\n",
    "        output = row['label']\n",
    " \n",
    "        prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "                    You are a clever AI agent which can discern between genuine and fake twitter profiles.You will be provided with the accounts metadata information.\n",
    "                    Please use these to classify the following twitter user as \"human\" or \"bot\". <|eot_id|>\n",
    "                    \n",
    "                    <|start_header_id|>user<|end_header_id|>\n",
    "                    \n",
    "                    ### MetaData Information:\n",
    "                    {prompt_text}\n",
    "                    \n",
    "                    <|eot_id|>\n",
    "                    \n",
    "                    ### Response: <|start_header_id|>assistant<|end_header_id|>\n",
    "                    {output}\"\"\"\n",
    "        \n",
    "        data.append({\n",
    "            'text': prompt\n",
    "        })\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a252a88f-ef3b-472a-83df-d89245a58280",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_finetuning_data(user_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0a14be4-b321-48c4-81fb-298d44323652",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = prepare_finetuning_data(user_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c50f8e9-cfed-42ee-8456-3553c5899474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/rachita/.local/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home1/rachita/.local/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "2024-12-15 16:12:19.283303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734307940.774302   20477 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734307941.335931   20477 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-15 16:12:23.247952: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [06:10<00:00, 92.50s/it] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "hf_token = \"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\"\n",
    "\n",
    "# Replace with the model identifier\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model with the token\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token, device_map=\"auto\", torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fd5e5e9-d51a-4bb0-adb8-e7f42d5a4aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 700000/700000 [01:31<00:00, 7626.96 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)\n",
    "\n",
    "# Assuming you have a dataset of inputs and outputs\n",
    "dataset = Dataset.from_list(data)\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4bc0f263-671d-49c4-b5f0-6b85ecf884e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (4/4 shards): 100%|██████████| 700000/700000 [00:01<00:00, 599393.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset.save_to_disk(\"Data/tokenized_user_meta_dataset_sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42dc4944-f6b8-46db-918c-3260dc82dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200000/200000 [00:38<00:00, 5183.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = Dataset.from_list(val_data)\n",
    "val_tokenized_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "691ee0e6-c747-4b35-9927-584c8a5eb340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (5/5 shards): 100%|██████████| 700000/700000 [00:02<00:00, 270641.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset.save_to_disk(\"Data/tokenized_user_meta_dataset_sft_val_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6c4a6d0-3c23-49b0-b850-2fea06d25c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8162939, 4)\n"
     ]
    }
   ],
   "source": [
    "parquet_file_path = 'Data/Tweet_SingleFile_Split/tweets_train_0.parquet'\n",
    "\n",
    "tweet_df_train = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "print(tweet_df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e8df420-f83a-422c-a495-e47d7171b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_tweet_df_train = pd.DataFrame(tweet_df_train.sample(n=700000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2678e2fd-2a90-47c7-8175-309860392274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_finetuning_tweet_data(training_data):\n",
    "    \"\"\"Prepares data for fine-tuning with QLoRA.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    for i, row in training_data.iterrows():\n",
    "        text = row['text']\n",
    "        output = row['label']\n",
    " \n",
    "        prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "                    You are a clever AI agent which can discern between genuine and fake twitter profiles.You will be provided with the tweet posted by the user.\n",
    "                    Please use these to classify the following twitter user as \"human\" or \"bot\". <|eot_id|>\n",
    "                    \n",
    "                    <|start_header_id|>user<|end_header_id|>\n",
    "                    \n",
    "                    ### Tweet:\n",
    "                    {text}\n",
    "                    \n",
    "                    <|eot_id|>\n",
    "                    \n",
    "                    ### Response: <|start_header_id|>assistant<|end_header_id|>\n",
    "                    {output}\"\"\"\n",
    "        \n",
    "        data.append({\n",
    "            'text': prompt\n",
    "        })\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "438fd4fe-30e2-4805-8ff8-01a1006a31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_sft = prepare_finetuning_tweet_data(sampled_tweet_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3c3ce27-1a63-490c-87d1-3f6524220549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 700000/700000 [01:28<00:00, 7934.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tweet_dataset = Dataset.from_list(data)\n",
    "tokenized_tweet_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "08fc1527-4398-4c93-a853-18a3512d4e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (4/4 shards): 100%|██████████| 700000/700000 [00:01<00:00, 443237.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_tweet_dataset.save_to_disk(\"Data/tokenized_user_tweet_dataset_sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d9d0e-604a-484b-b752-182d60d3ac3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
