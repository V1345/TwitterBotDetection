{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10219723,"sourceType":"datasetVersion","datasetId":6317584},{"sourceId":200547,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":171089,"modelId":193411}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom peft import PeftModelForCausalLM\nfrom datasets import load_from_disk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:50:55.892791Z","iopub.execute_input":"2024-12-17T03:50:55.893133Z","iopub.status.idle":"2024-12-17T03:51:03.157363Z","shell.execute_reply.started":"2024-12-17T03:50:55.893093Z","shell.execute_reply":"2024-12-17T03:51:03.156409Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nbase_model_path = \"meta-llama/Llama-3.1-8B-Instruct\"\nhf_token = \"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\"\nbase_model = AutoModelForCausalLM.from_pretrained(\n    base_model_path, \n    use_auth_token=hf_token, \n    device_map=\"auto\", \n    torch_dtype=\"auto\",\n    load_in_4bit = True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:51:03.175437Z","iopub.execute_input":"2024-12-17T03:51:03.175680Z","iopub.status.idle":"2024-12-17T03:58:10.245422Z","shell.execute_reply.started":"2024-12-17T03:51:03.175654Z","shell.execute_reply":"2024-12-17T03:58:10.244413Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b321758375f4606a1f79d5834e2e0e6"}},"metadata":{}},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebaa58668dce4e8abcd7b0f1398f638e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0b0fa839434ccaa9e9faf58f3e62e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6fccc4f018941f48e25eab1cb7af901"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c6074112d9e458480b1c6358789e022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8522efc9beac4b18a77b6a4f8d63c8db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7f604646c1c42b1a67a8aaea588badc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"353495600ff54a83979f4abed59730c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a900d8b92f1043c384baa24a6d809a58"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model_path,use_auth_token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:58:10.247586Z","iopub.execute_input":"2024-12-17T03:58:10.247861Z","iopub.status.idle":"2024-12-17T03:58:13.853983Z","shell.execute_reply.started":"2024-12-17T03:58:10.247836Z","shell.execute_reply":"2024-12-17T03:58:13.853277Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5170870bb3b34ee9a0cf994eacd2c608"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"372bcbdba6eb4814b2e979bb667c98e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec9e32752074f858e0be3491e196692"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from peft import PeftModelForCausalLM\nadapter_path = \"/kaggle/input/finetuned_llama_text/transformers/default/1\"\nmodel = PeftModelForCausalLM.from_pretrained(base_model, adapter_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:58:13.854991Z","iopub.execute_input":"2024-12-17T03:58:13.855301Z","iopub.status.idle":"2024-12-17T03:58:16.227767Z","shell.execute_reply.started":"2024-12-17T03:58:13.855267Z","shell.execute_reply":"2024-12-17T03:58:16.226958Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import pipeline\n\nllm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:58:16.228918Z","iopub.execute_input":"2024-12-17T03:58:16.229208Z","iopub.status.idle":"2024-12-17T03:58:16.235761Z","shell.execute_reply.started":"2024-12-17T03:58:16.229181Z","shell.execute_reply":"2024-12-17T03:58:16.234848Z"}},"outputs":[{"name":"stderr","text":"The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from datasets import load_from_disk\ndataset_path = \"/kaggle/input/inference-textdata\"\ndataset = load_from_disk(dataset_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:00:45.687370Z","iopub.execute_input":"2024-12-17T04:00:45.687728Z","iopub.status.idle":"2024-12-17T04:00:45.710115Z","shell.execute_reply.started":"2024-12-17T04:00:45.687698Z","shell.execute_reply":"2024-12-17T04:00:45.709003Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def parse_output(op):\n    if \"human\" in op:\n        return \"human\"\n    else:\n        return \"bot\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:01:44.973055Z","iopub.execute_input":"2024-12-17T04:01:44.973686Z","iopub.status.idle":"2024-12-17T04:01:44.977994Z","shell.execute_reply.started":"2024-12-17T04:01:44.973653Z","shell.execute_reply":"2024-12-17T04:01:44.977073Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Function to process batches\nBATCH_SIZE = 32\n\ndef process_batch(batch):\n    outputs = llm_pipeline(\n        batch[\"prompt\"],\n        max_new_tokens=5,\n        do_sample=True,\n        truncation=True,\n        return_full_text=False,\n        temperature=0.1,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    cleaned_outputs = [parse_output(output[0][\"generated_text\"]) for output in outputs]\n    # print(cleaned_outputs)\n    # cleaned_series = np.array(cleaned_outputs).reshape(1,5)                         \n    return {\"predictions\": cleaned_outputs}\n\n# Process dataset in batches\nbatched_results = dataset.map(\n    process_batch,\n    batched=True,\n    batch_size=BATCH_SIZE,\n    remove_columns=[\"prompt\"]  # Keep only necessary columns\n)\n# batched_results.save_to_disk(\"/kaggle/working/processed_data\")\n# Extract results\npredictions = batched_results[\"predictions\"]\nground_truths = batched_results[\"ground_truth\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:01:48.548816Z","iopub.execute_input":"2024-12-17T04:01:48.549156Z","iopub.status.idle":"2024-12-17T05:26:40.392736Z","shell.execute_reply.started":"2024-12-17T04:01:48.549127Z","shell.execute_reply":"2024-12-17T05:26:40.391741Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8acbac165b9c4d4a860efb5e94b88f83"}},"metadata":{}},{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\n\ndef calculate_metrics(ground_truth, predictions):\n    # Initialize the LabelEncoder\n    label_encoder = LabelEncoder()\n    \n    # Fit the encoder to the unique labels in ground_truth (and predictions)\n    ground_truth_encoded = label_encoder.fit_transform(ground_truth)\n    predictions_encoded = label_encoder.transform(predictions)  # Transform predictions\n    \n    # Accuracy calculation\n    accuracy = accuracy_score(ground_truth_encoded, predictions_encoded)\n    \n    # Precision calculation\n    precision = precision_score(ground_truth_encoded, predictions_encoded, average='weighted')\n    \n    # Recall calculation\n    recall = recall_score(ground_truth_encoded, predictions_encoded, average='weighted')\n    \n    # F1 Score calculation\n    f1 = f1_score(ground_truth_encoded, predictions_encoded, average='weighted')\n    \n    return accuracy, precision, recall, f1\n\n\naccuracy, precision, recall, f1 = calculate_metrics(ground_truths, predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T05:27:25.080227Z","iopub.execute_input":"2024-12-17T05:27:25.080825Z","iopub.status.idle":"2024-12-17T05:27:25.093958Z","shell.execute_reply.started":"2024-12-17T05:27:25.080792Z","shell.execute_reply":"2024-12-17T05:27:25.093063Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1 Score: {f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T05:57:58.022154Z","iopub.execute_input":"2024-12-17T05:57:58.022880Z","iopub.status.idle":"2024-12-17T05:57:58.027747Z","shell.execute_reply.started":"2024-12-17T05:57:58.022848Z","shell.execute_reply":"2024-12-17T05:57:58.026782Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6875\nPrecision: 0.59877\nRecall: 0.67133\nF1 Score: 0.6345\n","output_type":"stream"}],"execution_count":28}]}