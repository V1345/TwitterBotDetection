{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7287c836-2a8f-4aac-bf41-c984e1095be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7378380e-b33f-49c9-8b24-5c9e7d2c6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_json(\"Data/user.json\")\n",
    "split_df = pd.read_csv(\"Data/split.csv\")\n",
    "label_df = pd.read_csv(\"Data/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7644681f-f908-4042-8b71-026c461fe935",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_id_list = split_df[split_df['split']=='test']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e6f1d5-5a87-4a4a-9e84-db786fab26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_label = pd.merge(user_df,label_df,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6053c6-49cf-4663-8cd4-54982dd0fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_account_age(age):\n",
    "    if age == 0:\n",
    "        return \"account created less than a year ago\"\n",
    "    elif age == 1:\n",
    "        return \"account is 1 year old\"\n",
    "    else:\n",
    "        return f\"account is {age} years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9fc3a8-565a-49d1-ad88-7064f215862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (user_df_label['verified'] & user_df_label['protected']),            \n",
    "    (user_df_label['verified'] & ~user_df_label['protected']),           \n",
    "    (~user_df_label['verified'] & user_df_label['protected']),          \n",
    "    (~user_df_label['verified'] & ~user_df_label['protected'])        \n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    'verified and protected',\n",
    "    'verified but not protected',\n",
    "    'protected but not verified',\n",
    "    'neither verified nor protected'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f130c3-025f-4089-a05f-33824e9d2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now(pytz.UTC)\n",
    "user_df_label['account_age'] = user_df_label['created_at'].apply(lambda x: (current_date - x).days / 365.25)\n",
    "user_df_label['account_age'] = user_df_label['account_age'].apply(lambda x: np.nan if x > 19 else x)\n",
    "user_df_label['account_age'] = user_df_label.groupby('label')['account_age'].transform(lambda grp: grp.fillna(grp.mean()))\n",
    "user_df_label['account_age']= user_df_label['account_age'].astype(int)\n",
    "user_df_label['account_age'] = user_df_label['account_age'].apply(classify_account_age)\n",
    "user_df_label['followers_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('followers_count', 0))\n",
    "user_df_label['following_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('following_count', 0))\n",
    "user_df_label['tweet_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('tweet_count', 0))\n",
    "user_df_label['listed_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('listed_count', 0))\n",
    "user_df_label['status'] = np.select(conditions, choices, default='Unknown')\n",
    "user_df_label['has_custom_profile_image'] = user_df_label['profile_image_url'].apply(lambda x: \"does not have a profile picture\" if 'default_profile_images' in x else \"has a profile picture\")\n",
    "user_df_label.drop([\"protected\",\"verified\",\"created_at\",\"public_metrics\",\"entities\",\"location\",\"withheld\",\"pinned_tweet_id\",\"profile_image_url\",\"url\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb7fd6d-ba91-4fc6-ad5b-a40eb3e51ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>label</th>\n",
       "      <th>account_age</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>status</th>\n",
       "      <th>has_custom_profile_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Theoretical Computer Scientist. See also https...</td>\n",
       "      <td>u1217628182611927040</td>\n",
       "      <td>Boaz Barak</td>\n",
       "      <td>boazbaraktcs</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 4 years old</td>\n",
       "      <td>7316</td>\n",
       "      <td>215</td>\n",
       "      <td>3098</td>\n",
       "      <td>69</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creative _</td>\n",
       "      <td>u2664730894</td>\n",
       "      <td>olawale ðŸ’¨</td>\n",
       "      <td>wale_io</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 10 years old</td>\n",
       "      <td>123</td>\n",
       "      <td>1090</td>\n",
       "      <td>1823</td>\n",
       "      <td>0</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸ‘½</td>\n",
       "      <td>u1266703520205549568</td>\n",
       "      <td>panagiota_.b</td>\n",
       "      <td>b_panagiota</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 4 years old</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mama to maya. ABIM research pathway fellow @UV...</td>\n",
       "      <td>u1089159225148882949</td>\n",
       "      <td>Jacqueline Hodges, MD MPH</td>\n",
       "      <td>jachodges_md</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 5 years old</td>\n",
       "      <td>350</td>\n",
       "      <td>577</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father / SWT Alumnus / Longhorn Fan</td>\n",
       "      <td>u36741729</td>\n",
       "      <td>Matthew Stubblefield</td>\n",
       "      <td>Matthew_Brody</td>\n",
       "      <td>bot</td>\n",
       "      <td>account is 15 years old</td>\n",
       "      <td>240</td>\n",
       "      <td>297</td>\n",
       "      <td>3713</td>\n",
       "      <td>8</td>\n",
       "      <td>protected but not verified</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                    id  \\\n",
       "0  Theoretical Computer Scientist. See also https...  u1217628182611927040   \n",
       "1                                         creative _           u2664730894   \n",
       "2                                                  ðŸ‘½  u1266703520205549568   \n",
       "3  mama to maya. ABIM research pathway fellow @UV...  u1089159225148882949   \n",
       "4                Father / SWT Alumnus / Longhorn Fan             u36741729   \n",
       "\n",
       "                        name       username  label              account_age  \\\n",
       "0                 Boaz Barak   boazbaraktcs  human   account is 4 years old   \n",
       "1                  olawale ðŸ’¨        wale_io  human  account is 10 years old   \n",
       "2               panagiota_.b    b_panagiota  human   account is 4 years old   \n",
       "3  Jacqueline Hodges, MD MPH   jachodges_md  human   account is 5 years old   \n",
       "4       Matthew Stubblefield  Matthew_Brody    bot  account is 15 years old   \n",
       "\n",
       "   followers_count  following_count  tweet_count  listed_count  \\\n",
       "0             7316              215         3098            69   \n",
       "1              123             1090         1823             0   \n",
       "2                3               62           66             0   \n",
       "3              350              577          237             1   \n",
       "4              240              297         3713             8   \n",
       "\n",
       "                           status has_custom_profile_image  \n",
       "0  neither verified nor protected    has a profile picture  \n",
       "1  neither verified nor protected    has a profile picture  \n",
       "2  neither verified nor protected    has a profile picture  \n",
       "3  neither verified nor protected    has a profile picture  \n",
       "4      protected but not verified    has a profile picture  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed5303b-ee14-4bde-b20d-730f26eae58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data_prompt(feature_list):\n",
    "    user_metadata_text = f\"\"\"\n",
    "    The name of the user is '{feature_list['name']}' with an account username '{feature_list['username']}'. The description for the user profile is '{feature_list['description']}'. The {feature_list['account_age']} and some of the metric of the user is as follows:\n",
    "    The user has {feature_list['followers_count']} followers and follows {feature_list['following_count']} accounts. \n",
    "    The user has posted {feature_list['tweet_count']} tweets and is a member of {feature_list['listed_count']} public list.\n",
    "    The user account is {feature_list['status']} and it {feature_list['has_custom_profile_image']} associated with it.\n",
    "    \"\"\"\n",
    "    return user_metadata_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea212a4c-143c-448d-be79-af1e0d5c2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data_with_label(feature_list):\n",
    "    user_metadata_text = f\"\"\"\n",
    "    The name of the user is '{feature_list['name']}' with an account username '{feature_list['username']}'. The description for the user profile is '{feature_list['description']}'. The {feature_list['account_age']} and some of the metric of the user is as follows:\n",
    "    The user has {feature_list['followers_count']} followers and follows {feature_list['following_count']} accounts. \n",
    "    The user has posted {feature_list['tweet_count']} tweets and is a member of {feature_list['listed_count']} public list.\n",
    "    The user account is {feature_list['status']} and it {feature_list['has_custom_profile_image']} associated with it.\n",
    "\n",
    "    The account is actually a {feature_list['label']}\n",
    "    \"\"\"\n",
    "    return user_metadata_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c44e81-4587-4c15-9750-3c6650f07e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/rachita/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home1/rachita/.local/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home1/rachita/.local/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "2024-12-16 08:49:04.577566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734367745.202452    6353 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734367745.540036    6353 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-16 08:49:06.515612: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:29<00:00, 37.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "hf_token = \"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\"\n",
    "\n",
    "# Replace with the model identifier\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model with the token\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token, device_map=\"auto\", torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf225a6e-9683-41d3-94bb-d5410e6ccc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bccd2c1a-ff2e-4972-a804-e1b3d68f318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(op):\n",
    "    if \"human\" in op:\n",
    "        return \"human\"\n",
    "    else:\n",
    "        return \"bot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c53c30-7306-48c2-a1a9-a9c8f5e9d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_samples(user_df_label,num_samples=10):\n",
    "    sampled_df = user_df_label.sample(n=num_samples, random_state=42)\n",
    "    all_prompts = []\n",
    "    for _, row in sampled_df.iterrows():\n",
    "        # Generate the user data prompt\n",
    "        user_data_prompt = get_user_data_with_label(row)\n",
    "        \n",
    "        # Append the generated prompt to the list\n",
    "        all_prompts.append(user_data_prompt)\n",
    "    \n",
    "    # Join all prompts into a single string, separated by newlines\n",
    "    incontext_example = \"\\n\\n\".join(all_prompts)\n",
    "    \n",
    "    return incontext_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0c24f17-821e-49ce-9e6a-653a6d69ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 08:54:24,140 - INFO - Starting prompt preparation for 10000 test IDs in 157 batches of size 64.\n",
      "2024-12-16 09:02:44,531 - INFO - Successfully prepared 10000 out of 10000 prompts.\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 359261.31 examples/s]\n",
      "2024-12-16 09:02:45,011 - INFO - Dataset successfully saved to Data/user_meta_dataset\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datasets import Dataset\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "    level=logging.INFO  # You can change to DEBUG for more verbose logs\n",
    ")\n",
    "\n",
    "def prepare_prompt(test):\n",
    "    \"\"\"Prepares a single prompt for the given test user.\"\"\"\n",
    "    try:\n",
    "        feature_list = user_df_label.set_index('id').loc[test]\n",
    "        incontext_info = get_user_samples(user_df_label)\n",
    "        prompt_text = get_user_data_prompt(feature_list)\n",
    "    \n",
    "        prompt = f\"\"\"\n",
    "        You are a clever AI agent which can discern between genuine and fake twitter profiles. \n",
    "        You will be provided with the accounts metadata information along with several examples of genuine and fake users.\n",
    "        Please use these to classify the following twitter user as \"human\" or \"bot\"\n",
    "    \n",
    "        Relevant_Examples : {incontext_info}\n",
    "    \n",
    "        Metadata_Info: {prompt_text}\n",
    "    \n",
    "        Your output must be the label either <human> or <bot>. Do not write any explanation or reasoning.\n",
    "        \"\"\"\n",
    "    \n",
    "        return {\n",
    "            \"id\": test,\n",
    "            \"ground_truth\": feature_list[\"label\"],\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error preparing prompt for user ID {test}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_batch(batch):\n",
    "    \"\"\"Processes a batch of test IDs.\"\"\"\n",
    "    results = []\n",
    "    for test in batch:\n",
    "        result = prepare_prompt(test)\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "def parallel_prepare_prompts(test_ids, batch_size=64, n_jobs=-1):\n",
    "    \"\"\"Prepare prompts in parallel for a list of test IDs.\"\"\"\n",
    "    total = len(test_ids)\n",
    "    total_batches = math.ceil(total / batch_size)\n",
    "    \n",
    "    logging.info(f\"Starting prompt preparation for {total} test IDs in {total_batches} batches of size {batch_size}.\")\n",
    "    \n",
    "    # Split the test_ids into chunks of batch_size\n",
    "    batches = [test_ids[i:i + batch_size] for i in range(0, total, batch_size)]\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs, backend=\"multiprocessing\")(\n",
    "        delayed(process_batch)(batch) for batch in batches\n",
    "    )\n",
    "    \n",
    "    # Flatten the list of lists of results\n",
    "    valid_results = [res for batch_results in results for res in batch_results if res is not None]\n",
    "    \n",
    "    logging.info(f\"Successfully prepared {len(valid_results)} out of {total} prompts.\")\n",
    "    return valid_results\n",
    "\n",
    "# Generate dataset\n",
    "data = parallel_prepare_prompts(testing_id_list[:10000])\n",
    "\n",
    "if data:  # Only save if data is successfully prepared\n",
    "    dataset = Dataset.from_list(data)\n",
    "    dataset_path = \"Data/user_meta_dataset\"\n",
    "    try:\n",
    "        dataset.save_to_disk(dataset_path)\n",
    "        logging.info(f\"Dataset successfully saved to {dataset_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save dataset to {dataset_path}: {e}\")\n",
    "else:\n",
    "    logging.warning(\"No data was prepared. Dataset will not be saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "139c45b7-ba8a-42dc-9c41-1726075b695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   5%|â–Œ         | 512/10000 [02:04<38:35,  4.10 examples/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [40:49<00:00,  4.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to process batches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def process_batch(batch):\n",
    "    outputs = llm_pipeline(\n",
    "        batch[\"prompt\"],\n",
    "        max_new_tokens=5,\n",
    "        do_sample=True,\n",
    "        truncation=True,\n",
    "        return_full_text=False,\n",
    "        temperature=0.1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    cleaned_outputs = [parse_output(output[0][\"generated_text\"]) for output in outputs]\n",
    "    # print(cleaned_outputs)\n",
    "    # cleaned_series = np.array(cleaned_outputs).reshape(1,5)                         \n",
    "    return {\"predictions\": cleaned_outputs}\n",
    "\n",
    "# Process dataset in batches\n",
    "batched_results = dataset.map(\n",
    "    process_batch,\n",
    "    batched=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    remove_columns=[\"prompt\"]  # Keep only necessary columns\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "predictions = batched_results[\"predictions\"]\n",
    "ground_truths = batched_results[\"ground_truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70102c88-f6e9-4394-a099-3d12d9ce8a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7669\n",
      "Precision: 0.58813561\n",
      "Recall: 0.7669\n",
      "F1 Score: 0.6657259720414285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/rachita/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def calculate_metrics(ground_truth, predictions):\n",
    "    # Initialize the LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit the encoder to the unique labels in ground_truth (and predictions)\n",
    "    ground_truth_encoded = label_encoder.fit_transform(ground_truth)\n",
    "    predictions_encoded = label_encoder.transform(predictions)  # Transform predictions\n",
    "    \n",
    "    # Accuracy calculation\n",
    "    accuracy = accuracy_score(ground_truth_encoded, predictions_encoded)\n",
    "    \n",
    "    # Precision calculation\n",
    "    precision = precision_score(ground_truth_encoded, predictions_encoded, average='weighted')\n",
    "    \n",
    "    # Recall calculation\n",
    "    recall = recall_score(ground_truth_encoded, predictions_encoded, average='weighted')\n",
    "    \n",
    "    # F1 Score calculation\n",
    "    f1 = f1_score(ground_truth_encoded, predictions_encoded, average='weighted')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "accuracy, precision, recall, f1 = calculate_metrics(ground_truths, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96b8ad-b06f-4c36-99e0-47703dda6728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
