{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee9e8d4-134d-4a9a-ab24-069278fc818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0973e2b-1100-4a9a-a9d9-91d1e8245a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('jdk/17.0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7472a108-876f-4540-a11c-226f12aedf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/21 19:13:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b11-12.hpc.usc.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Our First Spark Example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f33e03d7980>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from typing import List\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark= SparkSession.builder.appName(\"Our First Spark Example\").config(\"spark.executor.memory\", \"108g\").config(\"spark.driver.memory\", \"72g\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7e783e-1a3d-42c9-85d2-92c8ec45480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736e6bc4-3007-4d99-aa60-a67ad94000bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = spark.read.parquet(\"Data/graph_data_user.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5618eaad-c95f-431d-bc9a-2651b390cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_data = graph_data.filter((graph_data.relation == \"followers\") | (graph_data.relation == \"following\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8253762-b568-429f-9e2a-48c01868fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|           source_id| relation|           target_id|\n",
      "+--------------------+---------+--------------------+\n",
      "| u980749991491682304|followers|u1480979504696864775|\n",
      "|          u105387876|following|          u402576793|\n",
      "|          u148520716|following|           u59653593|\n",
      "|u1276438425457967110|following|u1389155636693381120|\n",
      "|u1445432327367237638|following| u848348952084828160|\n",
      "|u1445432327367237638|following| u850507814023942144|\n",
      "|u1078324065532764166|following| u781676758932262912|\n",
      "|         u3185512585|following|           u19376807|\n",
      "|          u246495872|following|           u66780587|\n",
      "|         u2704715387|followers|u1483909830159085571|\n",
      "|         u4311016395|following|         u1281203928|\n",
      "|         u3254857712|following| u876448351268380672|\n",
      "|u1108086217088724992|following|          u213169506|\n",
      "|         u2750548111|following|           u25030647|\n",
      "|           u33746386|following|           u22730752|\n",
      "|u1093530573140824064|following|          u103865085|\n",
      "|u1295463204924067840|following|          u103865085|\n",
      "| u753165526566899713|followers|         u1484420078|\n",
      "|          u243286973|following|           u41405898|\n",
      "|           u81635029|following| u905563470707515394|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#graph_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72352c37-5523-46af-a156-51d0b47be00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3743634"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bc7234-0e64-4d5d-ac7f-43ec851a9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_count = graph_data.groupBy(\"relation\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc6ea71-4bb8-4ab3-9ea5-97ee2a22e2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=======================================================> (49 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "| relation|  count|\n",
      "+---------+-------+\n",
      "|followers|1116655|\n",
      "|following|2626979|\n",
      "+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "relation_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5457b9-a4df-412a-a160-ddbe542a67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in the 'source_id' column: 10009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======================================================> (49 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in the 'target_id' column: 693720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_count_source = graph_data.select(\"source_id\").distinct().count()\n",
    "print(f\"Number of unique values in the 'source_id' column: {unique_count_source}\")\n",
    "unique_count_target = graph_data.select(\"target_id\").distinct().count()\n",
    "print(f\"Number of unique values in the 'target_id' column: {unique_count_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc2f5da7-aab6-4efb-bd24-c1b627d120f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#graph_data.coalesce(1).write.parquet(\"Data/SparkOutput\",mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d437abd3-7c1c-4aee-9f29-51e70b7c189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_data = spark.read.option(\"multiline\", \"true\").json(\"Data/user.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407e2720-d0c0-4eab-aaf6-25007b87eef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_ids = [row.id for row in user_data.select(\"id\").collect()]\n",
    "\n",
    "# Filter graph_data using the list of user_ids\n",
    "graph_data = graph_data.filter(\n",
    "    (graph_data.source_id.isin(user_ids)) & (graph_data.target_id.isin(user_ids))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2503781d-d5a1-4fe6-917e-08cab8f152e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/21 03:38:04 WARN DAGScheduler: Broadcasting large task binary with size 142.4 MiB\n",
      "24/11/21 03:38:36 WARN DAGScheduler: Broadcasting large task binary with size 142.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10009"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data.select(\"source_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb20df9f-1d73-4212-9108-2d46a5a9d786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/21 03:35:20 WARN DAGScheduler: Broadcasting large task binary with size 83.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3743634"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7713c56d-bb8e-4c37-a328-7e73e0fb99f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[feature_a, feature_b]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[feature_b,feature_c]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[feature_c,feature_a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[feature_d,feature_e]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                features\n",
       "0   1  [feature_a, feature_b]\n",
       "1   2   [feature_b,feature_c]\n",
       "2   3   [feature_c,feature_a]\n",
       "3   4   [feature_d,feature_e]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86339dd-c3c7-433d-9fb4-925cecd106f4",
   "metadata": {},
   "source": [
    "# User Structural Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769517d4-2fc4-47df-b4b9-dcc73c93e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict, deque\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279dba3f-6db4-4ec9-87c3-81741598713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = pd.read_parquet(\"Data/graph_data_user.parquet\")\n",
    "user_df = pd.read_json(\"Data/user.json\")\n",
    "split_df = pd.read_csv(\"Data/split.csv\")\n",
    "label_df = pd.read_csv(\"Data/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869dca4a-b251-4fb5-97a9-607685348fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_id_list = split_df[split_df['split']=='test']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6594184-b802-45fc-bc80-68e0d60b0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_label = pd.merge(user_df,label_df,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e533b18-d0a5-4cb8-b9f2-c3f98862ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_no_rel(relation_df):\n",
    "    \"\"\"\n",
    "    Build an adjacency list graph from the relation dataset.\n",
    "    \"\"\"\n",
    "    graph = defaultdict(set)\n",
    "    \n",
    "    for _, row in relation_df.iterrows():\n",
    "        if row['relation'] == 'following':\n",
    "            graph[row['source_id']].add(row['target_id'])\n",
    "        elif row['relation'] == 'followers':\n",
    "            graph[row['target_id']].add(row['source_id'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f452f71-a9f5-43d5-8f91-8724a7e25be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_no_rel = build_graph_no_rel(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1b757d-f963-44b8-8d41-71cb622ce6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(relation_df):\n",
    "    \"\"\"\n",
    "    Build an adjacency list graph from the relation dataset with the type of relation.\n",
    "    \"\"\"\n",
    "    graph = defaultdict(lambda: {'following': set(), 'followers': set()})\n",
    "    \n",
    "    for _, row in relation_df.iterrows():\n",
    "        if row['relation'] == 'following':\n",
    "            graph[row['source_id']]['following'].add(row['target_id'])\n",
    "        elif row['relation'] == 'followers':\n",
    "            graph[row['target_id']]['followers'].add(row['source_id'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2405acc-e4f5-4d88-9901-fc615daa501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_graph(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0460938f-f435-4b53-99ff-7ae5e096494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_account_age(age):\n",
    "    if age == 0:\n",
    "        return \"account created less than a year ago\"\n",
    "    elif age == 1:\n",
    "        return \"account is 1 year old\"\n",
    "    else:\n",
    "        return f\"account is {age} years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de75b7a-8dc2-4a3c-a9ba-2a5b5441da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (user_df_label['verified'] & user_df_label['protected']),            \n",
    "    (user_df_label['verified'] & ~user_df_label['protected']),           \n",
    "    (~user_df_label['verified'] & user_df_label['protected']),          \n",
    "    (~user_df_label['verified'] & ~user_df_label['protected'])        \n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    'verified and protected',\n",
    "    'verified but not protected',\n",
    "    'protected but not verified',\n",
    "    'neither verified nor protected'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4e1bbf-d4b5-4a64-9b4b-ffe2095a3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now(pytz.UTC)\n",
    "user_df_label['account_age'] = user_df_label['created_at'].apply(lambda x: (current_date - x).days / 365.25)\n",
    "user_df_label['account_age'] = user_df_label['account_age'].apply(lambda x: np.nan if x > 19 else x)\n",
    "user_df_label['account_age'] = user_df_label.groupby('label')['account_age'].transform(lambda grp: grp.fillna(grp.mean()))\n",
    "user_df_label['account_age']= user_df_label['account_age'].astype(int)\n",
    "user_df_label['account_age'] = user_df_label['account_age'].apply(classify_account_age)\n",
    "user_df_label['followers_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('followers_count', 0))\n",
    "user_df_label['following_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('following_count', 0))\n",
    "user_df_label['tweet_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('tweet_count', 0))\n",
    "user_df_label['listed_count'] = user_df_label['public_metrics'].apply(lambda x: x.get('listed_count', 0))\n",
    "user_df_label['status'] = np.select(conditions, choices, default='Unknown')\n",
    "user_df_label['has_custom_profile_image'] = user_df_label['profile_image_url'].apply(lambda x: \"does not have a profile picture\" if 'default_profile_images' in x else \"has a profile picture\")\n",
    "user_df_label.drop([\"protected\",\"verified\",\"created_at\",\"public_metrics\",\"entities\",\"location\",\"withheld\",\"pinned_tweet_id\",\"profile_image_url\",\"url\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd9c9ad-a203-4a94-a230-137909d9ae11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>label</th>\n",
       "      <th>account_age</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>status</th>\n",
       "      <th>has_custom_profile_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Theoretical Computer Scientist. See also https...</td>\n",
       "      <td>u1217628182611927040</td>\n",
       "      <td>Boaz Barak</td>\n",
       "      <td>boazbaraktcs</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 4 years old</td>\n",
       "      <td>7316</td>\n",
       "      <td>215</td>\n",
       "      <td>3098</td>\n",
       "      <td>69</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creative _</td>\n",
       "      <td>u2664730894</td>\n",
       "      <td>olawale 💨</td>\n",
       "      <td>wale_io</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 10 years old</td>\n",
       "      <td>123</td>\n",
       "      <td>1090</td>\n",
       "      <td>1823</td>\n",
       "      <td>0</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>👽</td>\n",
       "      <td>u1266703520205549568</td>\n",
       "      <td>panagiota_.b</td>\n",
       "      <td>b_panagiota</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 4 years old</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mama to maya. ABIM research pathway fellow @UV...</td>\n",
       "      <td>u1089159225148882949</td>\n",
       "      <td>Jacqueline Hodges, MD MPH</td>\n",
       "      <td>jachodges_md</td>\n",
       "      <td>human</td>\n",
       "      <td>account is 5 years old</td>\n",
       "      <td>350</td>\n",
       "      <td>577</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>neither verified nor protected</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father / SWT Alumnus / Longhorn Fan</td>\n",
       "      <td>u36741729</td>\n",
       "      <td>Matthew Stubblefield</td>\n",
       "      <td>Matthew_Brody</td>\n",
       "      <td>bot</td>\n",
       "      <td>account is 15 years old</td>\n",
       "      <td>240</td>\n",
       "      <td>297</td>\n",
       "      <td>3713</td>\n",
       "      <td>8</td>\n",
       "      <td>protected but not verified</td>\n",
       "      <td>has a profile picture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                    id  \\\n",
       "0  Theoretical Computer Scientist. See also https...  u1217628182611927040   \n",
       "1                                         creative _           u2664730894   \n",
       "2                                                  👽  u1266703520205549568   \n",
       "3  mama to maya. ABIM research pathway fellow @UV...  u1089159225148882949   \n",
       "4                Father / SWT Alumnus / Longhorn Fan             u36741729   \n",
       "\n",
       "                        name       username  label              account_age  \\\n",
       "0                 Boaz Barak   boazbaraktcs  human   account is 4 years old   \n",
       "1                  olawale 💨        wale_io  human  account is 10 years old   \n",
       "2               panagiota_.b    b_panagiota  human   account is 4 years old   \n",
       "3  Jacqueline Hodges, MD MPH   jachodges_md  human   account is 5 years old   \n",
       "4       Matthew Stubblefield  Matthew_Brody    bot  account is 15 years old   \n",
       "\n",
       "   followers_count  following_count  tweet_count  listed_count  \\\n",
       "0             7316              215         3098            69   \n",
       "1              123             1090         1823             0   \n",
       "2                3               62           66             0   \n",
       "3              350              577          237             1   \n",
       "4              240              297         3713             8   \n",
       "\n",
       "                           status has_custom_profile_image  \n",
       "0  neither verified nor protected    has a profile picture  \n",
       "1  neither verified nor protected    has a profile picture  \n",
       "2  neither verified nor protected    has a profile picture  \n",
       "3  neither verified nor protected    has a profile picture  \n",
       "4      protected but not verified    has a profile picture  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e55327-5260-4949-93ef-0f6a8b1d9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_controlled_neighbors(user_id, graph, user_df, max_count=8):\n",
    "    \"\"\"\n",
    "    Get controlled number of followers and following for a given user while maintaining a bot-human ratio.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: ID of the user to fetch neighbors for.\n",
    "    - graph: The adjacency list representing the graph, with types of relations.\n",
    "    - user_df: DataFrame containing user features, including 'label' (bot or human).\n",
    "    - max_count: Maximum number of followers or following to fetch (default is 8).\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary with two keys ('followers', 'following'), each containing a list of user IDs.\n",
    "    \"\"\"\n",
    "    # Extract labels (bot/human) for users\n",
    "    label_dict = user_df.set_index('id')['label'].to_dict()  # {user_id: 'bot'/'human'}\n",
    "    \n",
    "    def select_users(user_set, target_count):\n",
    "        \"\"\"\n",
    "        Select a subset of users while maintaining a bot-to-human ratio close to 1.\n",
    "        \"\"\"\n",
    "        if not user_set:\n",
    "            return []\n",
    "        \n",
    "        # Separate bots and humans\n",
    "        bots = [user for user in user_set if label_dict.get(user) == 'bot']\n",
    "        humans = [user for user in user_set if label_dict.get(user) == 'human']\n",
    "        \n",
    "        # Calculate the ideal ratio of bots to humans\n",
    "        total = min(len(bots) + len(humans), target_count)\n",
    "        bot_target = total // 2\n",
    "        human_target = total - bot_target\n",
    "        \n",
    "        # Select users based on the targets\n",
    "        selected_bots = random.sample(bots, min(bot_target, len(bots)))\n",
    "        selected_humans = random.sample(humans, min(human_target, len(humans)))\n",
    "        \n",
    "        # Combine and return the selection\n",
    "        return selected_bots + selected_humans\n",
    "    \n",
    "    # Get followers and following\n",
    "    followers = graph.get(user_id, {}).get('followers', set())\n",
    "    following = graph.get(user_id, {}).get('following', set())\n",
    "    \n",
    "    # Select up to `max_count` followers and following while maintaining bot-human ratio\n",
    "    selected_followers = select_users(followers, max_count)\n",
    "    selected_following = select_users(following, max_count)\n",
    "    \n",
    "    return {\n",
    "        'followers': selected_followers,\n",
    "        'following': selected_following\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0c8a9e-aead-473a-9e3b-f4436c06d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_controlled_k_hop_neighbors(user_id, hops, graph, user_df):\n",
    "    \"\"\"\n",
    "    Get controlled k-hop neighbors for a given user with specified number of users per hop.\n",
    "    The method is optimized for large datasets by using efficient data structures and avoiding\n",
    "    unnecessary memory usage.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: ID of the user to start from.\n",
    "    - hops: List of integers specifying how many neighbors to sample at each hop (e.g., [3, 2]).\n",
    "    - graph: The adjacency list representing the graph.\n",
    "    - user_df: DataFrame containing user features.\n",
    "    \n",
    "    Returns:\n",
    "    - List of selected neighbors (user_id, features) per hop.\n",
    "    \"\"\"\n",
    "    # Extract only the relevant columns for user features\n",
    "    user_features_columns = user_df.columns.difference(['id'])  # Exclude the 'id' column\n",
    "    user_features_dict = user_df.set_index('id')[user_features_columns].to_dict(orient='index')\n",
    "\n",
    "    # BFS to find neighbors with controlled sample size at each hop\n",
    "    visited = set()\n",
    "    queue = deque([(user_id, 0)])  # (current_node, current_depth)\n",
    "    hop_neighbors = []  # Will hold neighbors for each hop\n",
    "\n",
    "    # For each hop level, select a specific number of neighbors\n",
    "    while queue:\n",
    "        current_node, depth = queue.popleft()\n",
    "\n",
    "        if depth < len(hops):  # We still have hops left to process\n",
    "            num_neighbors_at_depth = hops[depth]  # How many neighbors to select at this hop\n",
    "            neighbors_at_depth = set()\n",
    "\n",
    "            # Efficiently fetch neighbors from the graph\n",
    "            for neighbor in graph.get(current_node, []):\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    neighbors_at_depth.add(neighbor)\n",
    "\n",
    "            # Randomly select from neighbors_at_depth if needed\n",
    "            if len(neighbors_at_depth) > num_neighbors_at_depth:\n",
    "                selected_neighbors = random.sample(list(neighbors_at_depth), num_neighbors_at_depth)\n",
    "            else:\n",
    "                selected_neighbors = list(neighbors_at_depth)\n",
    "\n",
    "            # Add to the list of neighbors for this hop\n",
    "            hop_neighbors.append((depth + 1, selected_neighbors))\n",
    "\n",
    "            # Add selected neighbors to the queue for the next hop\n",
    "            for neighbor in selected_neighbors:\n",
    "                queue.append((neighbor, depth + 1))\n",
    "\n",
    "    # Fetch features for all selected neighbors in a memory-efficient way\n",
    "    selected_ids = set(neighbor for _, neighbors in hop_neighbors for neighbor in neighbors)\n",
    "    # selected_features = {user_id: user_features_dict[user_id] for user_id in selected_ids if user_id in user_features_dict}\n",
    "\n",
    "    return hop_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c714ccd-e027-4278-96ab-4f4411f4c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data_prompt(feature_list):\n",
    "    user_metadata_text = f\"\"\"\n",
    "    The name of the user is '{feature_list['name']}' with an account username '{feature_list['username']}'. The desciption for the user profile is '{feature_list['description']}'. The {feature_list['account_age']} and some of the metric of the user is as follows:\n",
    "    The user has {feature_list['followers_count']} followers and follows {feature_list['following_count']} accounts. \n",
    "    The user has posted {feature_list['tweet_count']} tweets and is a member of {feature_list['listed_count']} public list.\n",
    "    The user account is {feature_list['status']} and it {feature_list['has_custom_profile_image']} associated with it.\n",
    "    \"\"\"\n",
    "    return user_metadata_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66b28d76-8c79-4570-909e-824425818294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_text_no_rel(hop_neighbors):\n",
    "    structural_info = f\"\"\"\"\"\"\n",
    "    for hop in hop_neighbors:\n",
    "        hop_k, id_list = hop\n",
    "        structural_info += f\"At hop {hop_k} the user is related to these other users :\\n\"\n",
    "        for _id in id_list:\n",
    "            feature_list = user_df_label.set_index('id').loc[_id]\n",
    "            label = feature_list['label']\n",
    "            meta_text = get_user_data_prompt(feature_list)\n",
    "            structural_info += f\"{meta_text}\"\n",
    "            structural_info += f\"Label: {label}\\n\"\n",
    "        structural_info += \"\\n\"\n",
    "        structural_info+= \"---------------------------------------------------------------------------------------------------\"\n",
    "        structural_info += \"\\n\"\n",
    "    return structural_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a3c673c-e404-4a60-b4b0-ae1d16eacbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_text(neighbors_dict):\n",
    "    structural_info = f\"\"\"\"\"\"\n",
    "    followers_list = neighbors_dict['followers']\n",
    "    following_list = neighbors_dict['following']\n",
    "    if len(followers_list)>0:\n",
    "        structural_info += f\"Few of the accounts which follows the user are:\\n\"\n",
    "        for follower_id in followers_list:\n",
    "            feature_list = user_df_label.set_index('id').loc[follower_id]\n",
    "            label = feature_list['label']\n",
    "            meta_text = get_user_data_prompt(feature_list)\n",
    "            structural_info += f\"{meta_text}\"\n",
    "            structural_info += f\"Label: {label}\\n\"\n",
    "    else:\n",
    "        structural_info += f\"Could not find the accounts info which follows the user\"\n",
    "    structural_info += \"\\n\"\n",
    "    structural_info+= \"---------------------------------------------------------------------------------------------------\"\n",
    "    structural_info += \"\\n\"\n",
    "    if len(following_list)>0:\n",
    "        structural_info += f\"Few of the accounts which user is following are:\\n\"\n",
    "        for following_id in following_list:\n",
    "            feature_list = user_df_label.set_index('id').loc[following_id]\n",
    "            label = feature_list['label']\n",
    "            meta_text = get_user_data_prompt(feature_list)\n",
    "            structural_info += f\"{meta_text}\"\n",
    "            structural_info += f\"Label: {label}\\n\"\n",
    "    else:\n",
    "        structural_info += f\"Could not find the accounts info which user is following\"\n",
    "    structural_info += \"\\n\"\n",
    "    structural_info+= \"---------------------------------------------------------------------------------------------------\"\n",
    "    structural_info += \"\\n\"\n",
    "    return structural_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92387920-5e75-4d53-b524-dd9ac56d6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_dict = get_controlled_neighbors('u1493928389669015552',graph=graph,user_df=user_df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df4df51-9453-4315-b2a7-7b61b7289301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the accounts info which follows the user\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Could not find the accounts info which user is following\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(network_text(neighbors_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6ac43-d75a-4079-87c0-ab533ce908d8",
   "metadata": {},
   "source": [
    "# Setting up LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b1edc3e-abef-4a1f-98d6-c8ee8fa70507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/rachita/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home1/rachita/.local/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home1/rachita/.local/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "2024-12-16 09:33:17.328476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734370397.955316   26309 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734370398.105734   26309 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-16 09:33:19.100152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:27<00:00, 36.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "hf_token = \"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\"\n",
    "\n",
    "# Replace with the model identifier\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model with the token\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token, device_map=\"auto\", torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a3ac434-2c9b-4623-967f-78dff7678a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b4af580-e5fa-40f5-acbd-3c3f00e5f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(op):\n",
    "    if \"human\" in op:\n",
    "        return \"human\"\n",
    "    else:\n",
    "        return \"bot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e81ba69d-d0a1-490f-8ed2-d92cb4cd832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91d3c077-9a32-4517-b5d7-6d1c6830d2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 09:35:58,132 - INFO - Starting prompt preparation for 10000 test IDs in 157 batches of size 64.\n",
      "2024-12-16 10:34:59,119 - INFO - Successfully prepared 10000 out of 10000 prompts.\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 131896.35 examples/s]\n",
      "2024-12-16 10:34:59,748 - INFO - Dataset successfully saved to Data/user_rel_dataset\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datasets import Dataset\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "    level=logging.INFO  # You can change to DEBUG for more verbose logs\n",
    ")\n",
    "\n",
    "def prepare_prompt(test):\n",
    "    \"\"\"Prepares a single prompt for the given test user.\"\"\"\n",
    "    try:\n",
    "        feature_list = user_df_label.set_index('id').loc[test]\n",
    "        neighbors_dict = get_controlled_neighbors(test, graph, user_df_label)\n",
    "        structural_info = network_text(neighbors_dict)\n",
    "        prompt_text = get_user_data_prompt(feature_list)\n",
    "    \n",
    "        prompt = f\"\"\"\n",
    "        You are a clever AI agent which can discern between genuine and fake social media profiles. \n",
    "        You will be provided with the subset of account's structural information (follower/following relations) if available along with the metadata information.\n",
    "        Please use these to classify the following twitter user as \"human\" or \"bot\"\n",
    "    \n",
    "        Structural_Info: {structural_info}\n",
    "    \n",
    "        Metadata_Info: {prompt_text}\n",
    "    \n",
    "        Your output must be the label either <human> or <bot>. Do not write any explanation or reasoning.\n",
    "        \"\"\"\n",
    "    \n",
    "        return {\n",
    "            \"id\": test,\n",
    "            \"ground_truth\": feature_list[\"label\"],\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error preparing prompt for user ID {test}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_batch(batch):\n",
    "    \"\"\"Processes a batch of test IDs.\"\"\"\n",
    "    results = []\n",
    "    for test in batch:\n",
    "        result = prepare_prompt(test)\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "def parallel_prepare_prompts(test_ids, batch_size=64, n_jobs=-1):\n",
    "    \"\"\"Prepare prompts in parallel for a list of test IDs.\"\"\"\n",
    "    total = len(test_ids)\n",
    "    total_batches = math.ceil(total / batch_size)\n",
    "    \n",
    "    logging.info(f\"Starting prompt preparation for {total} test IDs in {total_batches} batches of size {batch_size}.\")\n",
    "    \n",
    "    # Split the test_ids into chunks of batch_size\n",
    "    batches = [test_ids[i:i + batch_size] for i in range(0, total, batch_size)]\n",
    "    \n",
    "    results = Parallel(n_jobs=n_jobs, backend=\"multiprocessing\")(\n",
    "        delayed(process_batch)(batch) for batch in batches\n",
    "    )\n",
    "    \n",
    "    # Flatten the list of lists of results\n",
    "    valid_results = [res for batch_results in results for res in batch_results if res is not None]\n",
    "    \n",
    "    logging.info(f\"Successfully prepared {len(valid_results)} out of {total} prompts.\")\n",
    "    return valid_results\n",
    "\n",
    "# Generate dataset\n",
    "data = parallel_prepare_prompts(testing_id_list[:10000])\n",
    "\n",
    "if data:  # Only save if data is successfully prepared\n",
    "    dataset = Dataset.from_list(data)\n",
    "    dataset_path = \"Data/user_rel_dataset\"\n",
    "    try:\n",
    "        dataset.save_to_disk(dataset_path)\n",
    "        logging.info(f\"Dataset successfully saved to {dataset_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save dataset to {dataset_path}: {e}\")\n",
    "else:\n",
    "    logging.warning(\"No data was prepared. Dataset will not be saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e705b84-95ef-40d2-af8c-e0e3d1ec9395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   6%|▋         | 640/10000 [04:09<1:00:08,  2.59 examples/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Map: 100%|██████████| 10000/10000 [51:46<00:00,  3.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to process batches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def process_batch(batch):\n",
    "    outputs = llm_pipeline(\n",
    "        batch[\"prompt\"],\n",
    "        max_new_tokens=5,\n",
    "        do_sample=True,\n",
    "        truncation=True,\n",
    "        return_full_text=False,\n",
    "        temperature=0.1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    cleaned_outputs = [parse_output(output[0][\"generated_text\"]) for output in outputs]\n",
    "    # print(cleaned_outputs)\n",
    "    # cleaned_series = np.array(cleaned_outputs).reshape(1,5)                         \n",
    "    return {\"predictions\": cleaned_outputs}\n",
    "\n",
    "# Process dataset in batches\n",
    "batched_results = dataset.map(\n",
    "    process_batch,\n",
    "    batched=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    remove_columns=[\"prompt\"]  # Keep only necessary columns\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "predictions = batched_results[\"predictions\"]\n",
    "ground_truths = batched_results[\"ground_truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba7d43ce-8d2a-4266-b373-5aff623a0fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7576\n",
      "Precision: 0.6556306245527956\n",
      "Recall: 0.7576\n",
      "F1 Score: 0.6717251845564474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def calculate_metrics(ground_truth, predictions):\n",
    "    # Initialize the LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Fit the encoder to the unique labels in ground_truth (and predictions)\n",
    "    ground_truth_encoded = label_encoder.fit_transform(ground_truth)\n",
    "    predictions_encoded = label_encoder.transform(predictions)  # Transform predictions\n",
    "    \n",
    "    # Accuracy calculation\n",
    "    accuracy = accuracy_score(ground_truth_encoded, predictions_encoded)\n",
    "    \n",
    "    # Precision calculation\n",
    "    precision = precision_score(ground_truth_encoded, predictions_encoded, average='weighted')\n",
    "    \n",
    "    # Recall calculation\n",
    "    recall = recall_score(ground_truth_encoded, predictions_encoded, average='weighted')\n",
    "    \n",
    "    # F1 Score calculation\n",
    "    f1 = f1_score(ground_truth_encoded, predictions_encoded, average='weighted')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "accuracy, precision, recall, f1 = calculate_metrics(ground_truths, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
